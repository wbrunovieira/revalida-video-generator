---
# Setup Ovi (Video + Audio) with isolated venv
# Run with: ansible-playbook playbook.yml --tags setup-ovi
#
# Creates: /mnt/models/Ovi-venv (isolated virtualenv)
# Used by: generate-video.sh when model=ovi
#
# Storage: Uses /mnt/models (500GB EBS mounted via mount-ebs.sh)

# ============================================
# MAIN SETUP STARTS HERE
# ============================================
- name: Display Ovi setup banner
  debug:
    msg: |
      ==========================================
      üé¨ SETTING UP OVI (Video + Audio)
      ==========================================
      Features:
      - 11B parameters (5B video + 5B audio)
      - Text-to-Video + Audio generation
      - Image-to-Video support
      - 720p/960p resolution
      - 5-10 seconds @ 24fps
      - FP8 quantization for 24GB VRAM
      - Isolated venv: {{ models_dir }}/Ovi-venv
      ==========================================
  tags: [setup-ovi]

# ============================================
# STEP 1: CLONE OVI REPOSITORY
# ============================================
- name: Check if Ovi code repository exists
  stat:
    path: "{{ models_dir }}/Ovi-code/.git"
  register: ovi_repo_check
  tags: [setup-ovi]

- name: Clone Ovi repository
  git:
    repo: https://github.com/character-ai/Ovi.git
    dest: "{{ models_dir }}/Ovi-code"
    version: main
    force: yes
  become_user: ubuntu
  when: not ovi_repo_check.stat.exists
  tags: [setup-ovi]

- name: Display Ovi repository status
  debug:
    msg: "‚úÖ Ovi code repository: {{ models_dir }}/Ovi-code"
  tags: [setup-ovi]

# ============================================
# STEP 2: CREATE ISOLATED OVI-VENV
# ============================================
- name: Check if Ovi-venv exists
  stat:
    path: "{{ models_dir }}/Ovi-venv/bin/activate"
  register: ovi_venv_check
  tags: [setup-ovi]

- name: Remove old Ovi-venv if broken
  file:
    path: "{{ models_dir }}/Ovi-venv"
    state: absent
  when: not ovi_venv_check.stat.exists
  tags: [setup-ovi]

- name: Create Ovi-venv
  command: python3 -m venv {{ models_dir }}/Ovi-venv
  become_user: ubuntu
  when: not ovi_venv_check.stat.exists
  tags: [setup-ovi]

- name: Display venv status
  debug:
    msg: "‚úÖ Ovi-venv created: {{ models_dir }}/Ovi-venv"
  tags: [setup-ovi]

# ============================================
# STEP 3: INSTALL DEPENDENCIES (PyTorch 2.6.0)
# ============================================
- name: Upgrade pip, wheel, setuptools in Ovi-venv
  pip:
    name:
      - pip
      - wheel
      - setuptools
      - ninja
      - packaging
    state: latest
    virtualenv: "{{ models_dir }}/Ovi-venv"
  become_user: ubuntu
  tags: [setup-ovi]

- name: Install PyTorch 2.6.0 with CUDA 12.4 (required for flash_attn)
  shell: |
    source {{ models_dir }}/Ovi-venv/bin/activate
    pip install torch==2.6.0 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124
  become_user: ubuntu
  args:
    executable: /bin/bash
  tags: [setup-ovi]

- name: Display PyTorch install status
  debug:
    msg: "‚úÖ PyTorch 2.6.0+cu124 installed"
  tags: [setup-ovi]

# ============================================
# STEP 4: INSTALL FLASH ATTENTION (pre-built wheel)
# ============================================
- name: Install Flash Attention 2 (pre-built wheel for PyTorch 2.6 + CUDA 12)
  shell: |
    source {{ models_dir }}/Ovi-venv/bin/activate
    pip uninstall flash-attn -y 2>/dev/null || true
    pip install https://github.com/Dao-AILab/flash-attention/releases/download/v2.7.4.post1/flash_attn-2.7.4.post1+cu12torch2.6cxx11abiFALSE-cp310-cp310-linux_x86_64.whl
  become_user: ubuntu
  args:
    executable: /bin/bash
  tags: [setup-ovi]
  ignore_errors: yes

- name: Verify flash_attn installation
  shell: |
    source {{ models_dir }}/Ovi-venv/bin/activate
    python -c "import flash_attn; print('flash_attn OK')"
  become_user: ubuntu
  args:
    executable: /bin/bash
  register: flash_attn_verify
  ignore_errors: yes
  tags: [setup-ovi]

- name: Display flash_attn status
  debug:
    msg: "{{ 'flash_attn: Installed ‚úÖ' if flash_attn_verify.rc == 0 else 'flash_attn: Failed (model may still work) ‚ö†Ô∏è' }}"
  tags: [setup-ovi]

# ============================================
# STEP 5: INSTALL OVI DEPENDENCIES
# ============================================
- name: Install Ovi additional dependencies
  pip:
    name:
      - einops
      - omegaconf
      - decord
      - imageio
      - imageio-ffmpeg
      - soundfile
      - librosa
      - diffusers
      - transformers
      - accelerate
      - huggingface-hub
      - opencv-python
      - Pillow
      - numpy
      - scipy
    virtualenv: "{{ models_dir }}/Ovi-venv"
  become_user: ubuntu
  tags: [setup-ovi]

- name: Install Ovi requirements from requirements.txt
  pip:
    requirements: "{{ models_dir }}/Ovi-code/requirements.txt"
    virtualenv: "{{ models_dir }}/Ovi-venv"
  become_user: ubuntu
  tags: [setup-ovi]
  ignore_errors: yes

- name: Display dependencies status
  debug:
    msg: "‚úÖ Ovi dependencies installed"
  tags: [setup-ovi]

# ============================================
# STEP 6: DOWNLOAD OVI MODEL WEIGHTS
# ============================================
- name: Check if Ovi 720x720_5s model is downloaded
  stat:
    path: "{{ models_dir }}/Ovi/720x720_5s"
  register: ovi_model_check
  tags: [setup-ovi]

- name: Download Ovi model and dependencies
  shell: |
    source {{ models_dir }}/Ovi-venv/bin/activate
    cd {{ models_dir }}/Ovi-code
    echo "üì• Downloading Ovi and all dependencies..."
    echo "   - Ovi model weights"
    echo "   - Wan2.2 VAE"
    echo "   - T5 text encoder"
    echo "   - MMAudio VAE"
    echo "This will take 20-30 minutes and download ~70GB"
    echo ""
    python3 download_weights.py --output-dir {{ models_dir }}/Ovi --models 720x720_5s
  become_user: ubuntu
  when: not ovi_model_check.stat.exists
  args:
    executable: /bin/bash
  async: 3600
  poll: 30
  tags: [setup-ovi]

- name: Verify Ovi model downloaded
  stat:
    path: "{{ models_dir }}/Ovi/720x720_5s"
  register: ovi_final_check
  tags: [setup-ovi]

- name: Display download status
  debug:
    msg: |
      Ovi 720x720_5s model: {{ 'Downloaded ‚úÖ' if ovi_final_check.stat.exists else 'Not found ‚ùå' }}
      Location: {{ models_dir }}/Ovi/
  tags: [setup-ovi]

# ============================================
# STEP 6.5: DOWNLOAD FP8 QUANTIZED MODEL
# Required for 24GB VRAM GPUs (A10G)
# FP8 model is in separate repo: rkfg/Ovi-fp8_quantized
# ============================================
- name: Check if FP8 quantized model exists
  stat:
    path: "{{ models_dir }}/Ovi/Ovi/model_fp8_e4m3fn.safetensors"
  register: fp8_model_check
  tags: [setup-ovi]

- name: Download FP8 quantized model for 24GB VRAM
  shell: |
    echo "üì• Downloading FP8 quantized model (~12GB)..."
    echo "   Source: huggingface.co/rkfg/Ovi-fp8_quantized"
    echo "   This enables running on single A10G (24GB VRAM)"
    wget -O "{{ models_dir }}/Ovi/Ovi/model_fp8_e4m3fn.safetensors" \
      "https://huggingface.co/rkfg/Ovi-fp8_quantized/resolve/main/model_fp8_e4m3fn.safetensors"
    echo "‚úÖ FP8 model downloaded!"
  become_user: ubuntu
  when: not fp8_model_check.stat.exists
  args:
    executable: /bin/bash
  async: 1800
  poll: 30
  tags: [setup-ovi]

- name: Verify FP8 model downloaded
  stat:
    path: "{{ models_dir }}/Ovi/Ovi/model_fp8_e4m3fn.safetensors"
  register: fp8_final_check
  tags: [setup-ovi]

- name: Display FP8 download status
  debug:
    msg: |
      FP8 quantized model: {{ 'Downloaded ‚úÖ' if fp8_final_check.stat.exists else 'Not found ‚ùå' }}
      Location: {{ models_dir }}/Ovi/Ovi/model_fp8_e4m3fn.safetensors
      Enables: Single GPU (24GB VRAM) inference with cpu_offload
  tags: [setup-ovi]

# ============================================
# STEP 7: CREATE INFERENCE CONFIG
# ============================================
- name: Create Ovi default inference config
  copy:
    dest: "{{ models_dir }}/Ovi-code/ovi/configs/inference/inference_24gb.yaml"
    content: |
      # Ovi Configuration for 24GB VRAM (A10G GPUs)
      # Optimized for G5.12xlarge (4x A10G)

      model_name: "720x720_5s"
      output_dir: "/mnt/output"
      ckpt_dir: "/mnt/models/Ovi"

      sample_steps: 50
      solver_name: "unipc"
      shift: 5.0
      seed: 42

      audio_guidance_scale: 3.0
      video_guidance_scale: 4.0
      slg_layer: 11

      # CRITICAL for 24GB VRAM
      sp_size: 1
      cpu_offload: True
      fp8: True

      mode: "t2v"
      text_prompt: "Italian doctor in white coat. Audio: Professional ambient music"
      video_frame_height_width: [720, 720]
      each_example_n_times: 1

      video_negative_prompt: "jitter, bad hands, blur, distortion"
      audio_negative_prompt: "robotic, muffled, echo, distorted"
    owner: ubuntu
    group: ubuntu
    mode: '0644'
  tags: [setup-ovi]

# ============================================
# STEP 8: COPY GENERATE-VIDEO SCRIPT
# ============================================
- name: Create application directory
  file:
    path: "{{ app_dir }}"
    state: directory
    owner: ubuntu
    group: ubuntu
    mode: '0755'
  tags: [setup-ovi]

- name: Copy generate-video.sh to server
  copy:
    src: "{{ playbook_dir }}/files/generate-video.sh"
    dest: "{{ app_dir }}/generate-video.sh"
    owner: ubuntu
    group: ubuntu
    mode: '0755'
  tags: [setup-ovi]

- name: Remove existing generate-video file (if not a symlink)
  file:
    path: /usr/local/bin/generate-video
    state: absent
  when: ansible_facts['distribution'] is defined  # always runs
  tags: [setup-ovi]

- name: Create symlink for generate-video
  file:
    src: "{{ app_dir }}/generate-video.sh"
    dest: /usr/local/bin/generate-video
    state: link
  tags: [setup-ovi]

# ============================================
# FINAL STATUS
# ============================================
- name: Verify complete installation
  shell: |
    source {{ models_dir }}/Ovi-venv/bin/activate
    echo "PyTorch: $(python -c 'import torch; print(torch.__version__)')"
    echo "CUDA: $(python -c 'import torch; print(torch.cuda.is_available())')"
    python -c "import flash_attn" && echo "flash_attn: OK" || echo "flash_attn: Not available"
    python -c "import einops" && echo "einops: OK" || echo "einops: Not available"
  become_user: ubuntu
  args:
    executable: /bin/bash
  register: install_verify
  tags: [setup-ovi]
  ignore_errors: yes

- name: Display setup complete
  debug:
    msg: |
      ==========================================
      ‚úÖ OVI SETUP COMPLETE
      ==========================================

      üìÅ Locations:
         Venv:    {{ models_dir }}/Ovi-venv
         Code:    {{ models_dir }}/Ovi-code
         Weights: {{ models_dir }}/Ovi
         Config:  {{ models_dir }}/Ovi-code/ovi/configs/inference/inference_24gb.yaml

      üîç Installation Check:
      {{ install_verify.stdout }}

      üé¨ Usage:
         generate-video ovi t2v "Your prompt. Audio: description"
         generate-video ovi i2v "Your prompt" /path/to/image.png

      üìù Or interactive mode:
         generate-video

      ==========================================
  tags: [setup-ovi]
