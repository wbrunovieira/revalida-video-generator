---
# Test CogVideoX-5B setup and generate test videos
# Run with: ansible-playbook playbook.yml --tags test-cogvideox

- name: Create CogVideoX single-GPU test script
  copy:
    dest: /mnt/output/test_cogvideox_single.py
    content: |
      #!/usr/bin/env python3
      """
      CogVideoX-5B Single-GPU Test Script
      Generates a test video to verify installation
      """
      import torch
      from diffusers import CogVideoXPipeline
      from diffusers.utils import export_to_video
      import time

      print("=" * 50)
      print("ðŸŽ¬ CogVideoX-5B Single-GPU Test")
      print("=" * 50)
      print()

      # Check CUDA availability
      print(f"PyTorch version: {torch.__version__}")
      print(f"CUDA available: {torch.cuda.is_available()}")
      print(f"CUDA version: {torch.version.cuda}")
      print(f"Number of GPUs: {torch.cuda.device_count()}")
      if torch.cuda.is_available():
          print(f"GPU 0: {torch.cuda.get_device_name(0)}")
          print(f"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB")
      print()

      # Load pipeline
      print("ðŸ“¦ Loading CogVideoX-5b model...")
      start_time = time.time()

      pipe = CogVideoXPipeline.from_pretrained(
          "/mnt/models/CogVideoX-5b",
          torch_dtype=torch.bfloat16
      )

      # Enable CPU offloading to save VRAM
      pipe.enable_model_cpu_offload()
      pipe.vae.enable_tiling()

      load_time = time.time() - start_time
      print(f"âœ… Model loaded in {load_time:.2f} seconds")
      print()

      # Generate video
      prompt = "Italian doctor in white coat examining medical charts in modern hospital, professional HD quality, cinematic lighting, realistic"

      print(f"ðŸŽ¨ Generating video with prompt:")
      print(f"   '{prompt}'")
      print()
      print("â³ This will take 3-5 minutes on single GPU...")
      print()

      gen_start = time.time()

      video = pipe(
          prompt=prompt,
          num_videos_per_prompt=1,
          num_inference_steps=50,
          num_frames=49,
          guidance_scale=6,
          generator=torch.Generator(device="cuda").manual_seed(42),
      ).frames[0]

      gen_time = time.time() - gen_start

      # Export video
      output_path = "/mnt/output/test_cogvideox_single.mp4"
      export_to_video(video, output_path, fps=8)

      print()
      print("=" * 50)
      print("âœ… VIDEO GENERATION COMPLETE!")
      print("=" * 50)
      print(f"Generation time: {gen_time:.2f} seconds ({gen_time/60:.2f} minutes)")
      print(f"Output: {output_path}")
      print(f"Frames: 49 @ 8fps (~6 seconds)")
      print("=" * 50)
    mode: '0755'
    owner: ubuntu
    group: ubuntu
  tags: [test-cogvideox, never]

- name: Create CogVideoX multi-GPU test script using xDiT
  copy:
    dest: /mnt/output/test_cogvideox_multi.py
    content: |
      #!/usr/bin/env python3
      """
      CogVideoX-5B Multi-GPU Test Script using xDiT proper API
      Run with: python test_cogvideox_multi.py --model /mnt/models/CogVideoX-5b \
                --ulysses_degree 2 --ring_degree 2 --height 480 --width 720 \
                --num_frames 49 --num_inference_steps 50 --use_cfg_parallel \
                --prompt "Italian doctor in white coat examining medical charts"
      """
      import torch
      import time
      import os
      import sys

      # Add xDiT to path
      sys.path.insert(0, '/mnt/models/xDiT')

      from xfuser import xFuserCogVideoXPipeline, xFuserArgs
      from xfuser.config import FlexibleArgumentParser
      from xfuser.core.distributed import (
          get_world_group,
          is_dp_last_group,
          get_runtime_state,
      )
      from diffusers.utils import export_to_video

      def main():
          parser = FlexibleArgumentParser(description="CogVideoX-5B Multi-GPU Test")
          args = xFuserArgs.add_cli_args(parser).parse_args()
          engine_args = xFuserArgs.from_cli_args(args)

          engine_config, input_config = engine_args.create_config()
          local_rank = get_world_group().local_rank

          if local_rank == 0:
              print("=" * 60)
              print("ðŸŽ¬ CogVideoX-5B Multi-GPU Test with xDiT")
              print("=" * 60)
              print(f"Model: {engine_config.model_config.model}")
              print(f"Ulysses degree: {engine_args.ulysses_degree}")
              print(f"Ring degree: {engine_args.ring_degree}")
              print(f"World size: {get_world_group().world_size}")
              print(f"Resolution: {input_config.width}x{input_config.height}")
              print(f"Frames: {input_config.num_frames}")
              print(f"Steps: {input_config.num_inference_steps}")
              print("=" * 60)
              print()

          # Load pipeline with xDiT
          if local_rank == 0:
              print("ðŸ“¦ Loading CogVideoX-5b with xDiT parallelism...")

          start_time = time.time()

          pipe = xFuserCogVideoXPipeline.from_pretrained(
              pretrained_model_name_or_path=engine_config.model_config.model,
              engine_config=engine_config,
              torch_dtype=torch.bfloat16,
          )

          if args.enable_model_cpu_offload:
              pipe.enable_model_cpu_offload(gpu_id=local_rank)
              if local_rank == 0:
                  print("âœ“ Model CPU offload enabled")
          else:
              device = torch.device(f"cuda:{local_rank}")
              pipe = pipe.to(device)

          if args.enable_tiling:
              pipe.vae.enable_tiling()
              if local_rank == 0:
                  print("âœ“ VAE tiling enabled")

          if args.enable_slicing:
              pipe.vae.enable_slicing()
              if local_rank == 0:
                  print("âœ“ VAE slicing enabled")

          load_time = time.time() - start_time
          if local_rank == 0:
              print(f"âœ… Model loaded in {load_time:.2f} seconds")
              print()

          # Warmup
          if local_rank == 0:
              print("â³ Warming up...")

          _ = pipe(
              height=input_config.height,
              width=input_config.width,
              num_frames=input_config.num_frames,
              prompt=input_config.prompt,
              num_inference_steps=1,
              generator=torch.Generator(device="cuda").manual_seed(input_config.seed),
          ).frames[0]

          if local_rank == 0:
              print("âœ… Warmup complete")
              print()
              print(f"ðŸŽ¨ Generating video:")
              print(f"   Prompt: '{input_config.prompt}'")
              print()

          # Generate video
          torch.cuda.reset_peak_memory_stats()
          gen_start = time.time()

          output = pipe(
              height=input_config.height,
              width=input_config.width,
              num_frames=input_config.num_frames,
              prompt=input_config.prompt,
              num_inference_steps=input_config.num_inference_steps,
              guidance_scale=input_config.guidance_scale,
              generator=torch.Generator(device="cuda").manual_seed(input_config.seed),
          ).frames[0]

          gen_time = time.time() - gen_start
          peak_memory = torch.cuda.max_memory_allocated(device=f"cuda:{local_rank}")

          # Save video (only last DP group)
          if is_dp_last_group():
              output_path = "/mnt/output/test_cogvideox_multi.mp4"
              export_to_video(output, output_path, fps=8)

              if local_rank == get_world_group().world_size - 1:
                  print()
                  print("=" * 60)
                  print("âœ… VIDEO GENERATION COMPLETE!")
                  print("=" * 60)
                  print(f"Generation time: {gen_time:.2f} seconds ({gen_time/60:.2f} minutes)")
                  print(f"Peak memory: {peak_memory/1e9:.2f} GB per GPU")
                  print(f"Output: {output_path}")
                  print(f"Frames: {input_config.num_frames} @ 8fps")
                  print("=" * 60)

          # Cleanup
          get_runtime_state().destroy_distributed_env()

      if __name__ == "__main__":
          main()
    mode: '0755'
    owner: ubuntu
    group: ubuntu
  tags: [test-cogvideox, never]

- name: Create CogVideoX test helper script
  copy:
    dest: /mnt/output/test_cogvideox.sh
    content: |
      #!/bin/bash
      # CogVideoX-5B Test Helper

      cd /mnt/output
      source /home/ubuntu/video-generation/venv/bin/activate

      echo "=========================================="
      echo "ðŸŽ¬ COGVIDEOX-5B TEST MENU"
      echo "=========================================="
      echo ""
      echo "Choose test mode:"
      echo "1. Single GPU (3-5 minutes, ~22GB VRAM)"
      echo "2. Multi GPU - 4 GPUs (1-2 minutes, 3.9x faster)"
      echo ""
      read -p "Enter choice [1 or 2]: " choice

      case $choice in
        1)
          echo ""
          echo "ðŸš€ Running single-GPU test..."
          python3 /mnt/output/test_cogvideox_single.py
          ;;
        2)
          echo ""
          echo "ðŸš€ Running multi-GPU test with 4 GPUs using xDiT..."
          echo ""

          PROMPT="Italian doctor in white coat examining medical charts in modern hospital, professional HD quality, cinematic lighting, realistic"

          torchrun --nproc_per_node=4 /mnt/output/test_cogvideox_multi.py \
            --model /mnt/models/CogVideoX-5b \
            --ulysses_degree 1 \
            --ring_degree 2 \
            --height 480 \
            --width 720 \
            --num_frames 49 \
            --num_inference_steps 50 \
            --use_cfg_parallel \
            --enable_model_cpu_offload \
            --enable_tiling \
            --enable_slicing \
            --seed 42 \
            --prompt "$PROMPT"
          ;;
        *)
          echo "Invalid choice. Please run again and select 1 or 2."
          exit 1
          ;;
      esac

      echo ""
      echo "âœ… Test complete! Check output files:"
      ls -lh /mnt/output/test_cogvideox*.mp4 2>/dev/null || echo "No videos found yet"
    mode: '0755'
    owner: ubuntu
    group: ubuntu
  tags: [test-cogvideox, never]

- name: Display CogVideoX test instructions
  debug:
    msg: |
      ==========================================
      ðŸ“‹ COGVIDEOX TEST READY
      ==========================================

      SSH into server and run:
      /mnt/output/test_cogvideox.sh

      Or run directly:

      Single GPU:
      cd /mnt/output && source ~/video-generation/venv/bin/activate
      python3 test_cogvideox_single.py

      Multi GPU (4 GPUs):
      cd /mnt/output && source ~/video-generation/venv/bin/activate
      torchrun --nproc_per_node=4 test_cogvideox_multi.py

      Expected times:
      - Single GPU: 3-5 minutes
      - Multi GPU:  1-2 minutes (3.91x speedup)

      Output: /mnt/output/test_cogvideox_*.mp4
      ==========================================
  tags: [test-cogvideox, never]
