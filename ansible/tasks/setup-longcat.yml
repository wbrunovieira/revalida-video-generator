---
# Setup LongCat-Video for T2V, I2V, and Video-Continuation
# Run with: ansible-playbook playbook.yml --tags setup-longcat

- name: Display LongCat setup banner
  debug:
    msg: |
      ==========================================
      ðŸ± SETTING UP LONGCAT-VIDEO
      ==========================================
      Features:
      - 13.6B parameters (dense architecture)
      - Text-to-Video, Image-to-Video, Video-Continuation
      - Long video generation (minutes-long)
      - 720p, 30fps output
      - Multi-GPU with context parallelism
      - FlashAttention-2 support
      ==========================================

# ============================================
# INSTALL LONGCAT DEPENDENCIES
# ============================================
- name: Install LongCat base dependencies
  pip:
    name:
      - ninja
      - psutil
      - packaging
      - einops
      - omegaconf
      - decord
      - imageio
      - imageio-ffmpeg
      - bitsandbytes
      - scipy
    virtualenv: "{{ app_dir }}/venv"
  become_user: ubuntu
  tags: [setup-longcat]

- name: Check if flash-attn is installed
  shell: |
    source {{ app_dir }}/venv/bin/activate
    pip show flash-attn || echo "not_installed"
  register: flash_attn_check
  become_user: ubuntu
  changed_when: false
  tags: [setup-longcat]
  args:
    executable: /bin/bash

- name: Install flash-attn if not present
  pip:
    name: flash_attn==2.7.4.post1
    virtualenv: "{{ app_dir }}/venv"
  become_user: ubuntu
  when: "'not_installed' in flash_attn_check.stdout"
  tags: [setup-longcat]

# ============================================
# CLONE LONGCAT REPOSITORY
# ============================================
- name: Clone LongCat-Video repository
  git:
    repo: https://github.com/meituan-longcat/LongCat-Video.git
    dest: "{{ models_dir }}/LongCat-Video-code"
    version: main
    force: yes
  become_user: ubuntu
  tags: [setup-longcat]

- name: Install LongCat requirements (excluding flash-attn)
  shell: |
    source {{ app_dir }}/venv/bin/activate
    cd {{ models_dir }}/LongCat-Video-code
    # Install requirements excluding flash-attn (already installed separately)
    grep -v "flash-attn" requirements.txt | pip install -r /dev/stdin
  become_user: ubuntu
  tags: [setup-longcat]
  args:
    executable: /bin/bash
  ignore_errors: yes

- name: Ensure flash-attn is installed (pre-built wheel)
  shell: |
    source {{ app_dir }}/venv/bin/activate
    # Check if already installed
    if pip show flash-attn > /dev/null 2>&1; then
      echo "flash-attn already installed"
    else
      # Install pre-built wheel for PyTorch 2.6 + CUDA 12.4
      pip install flash-attn --no-build-isolation
    fi
  become_user: ubuntu
  tags: [setup-longcat]
  args:
    executable: /bin/bash
  ignore_errors: yes

# ============================================
# DOWNLOAD LONGCAT MODEL
# ============================================
- name: Check if LongCat model exists
  stat:
    path: "{{ models_dir }}/LongCat-Video/config.json"
  register: longcat_model_check
  tags: [setup-longcat]

- name: Download LongCat-Video model (~27GB)
  shell: |
    source {{ app_dir }}/venv/bin/activate
    cd {{ models_dir }}
    echo "ðŸ“¥ Downloading LongCat-Video (~27GB, will take 20-40 minutes)..."
    huggingface-cli download meituan-longcat/LongCat-Video --local-dir LongCat-Video
  become_user: ubuntu
  when: not longcat_model_check.stat.exists
  tags: [setup-longcat]
  args:
    executable: /bin/bash
  async: 7200  # 2 hour timeout
  poll: 60    # Check every 60 seconds

- name: Verify model downloaded successfully
  stat:
    path: "{{ models_dir }}/LongCat-Video/config.json"
  register: longcat_final_check
  tags: [setup-longcat]

- name: Display model download status
  debug:
    msg: |
      LongCat-Video model: {{ 'Downloaded âœ…' if longcat_final_check.stat.exists else 'Failed âŒ' }}
      Location: {{ models_dir }}/LongCat-Video/
  tags: [setup-longcat]

# ============================================
# CREATE HELPER SCRIPTS
# ============================================
- name: Create LongCat T2V helper script (official approach)
  copy:
    dest: "{{ app_dir }}/longcat_t2v.sh"
    content: |
      #!/bin/bash
      # LongCat Text-to-Video - Official approach with torchrun
      # Usage: longcat_t2v.sh "your prompt here" [num_gpus]

      PROMPT="${1:-A cat walking on the beach at sunset}"
      NUM_GPUS="${2:-4}"

      source {{ app_dir }}/venv/bin/activate
      cd {{ models_dir }}/LongCat-Video-code

      echo "ðŸ± LongCat Text-to-Video (Official)"
      echo "   GPUs: $NUM_GPUS (context parallelism)"
      echo "   Compile: enabled (torch.compile)"
      echo "   Prompt: $PROMPT"
      echo ""

      # Clear GPU memory
      python3 -c "import torch; [torch.cuda.empty_cache() for _ in range(torch.cuda.device_count())]" 2>/dev/null

      # Backup original script
      cp run_demo_text_to_video.py run_demo_text_to_video.py.bak

      # Replace prompt in the demo script
      ESCAPED_PROMPT=$(echo "$PROMPT" | sed 's/[&/\]/\\&/g' | sed "s/'/\\\\'/g")
      sed -i "s|prompt = \".*\"|prompt = \"$ESCAPED_PROMPT\"|" run_demo_text_to_video.py

      # Run with official command
      if [ "$NUM_GPUS" -eq 1 ]; then
        torchrun run_demo_text_to_video.py \
          --checkpoint_dir={{ models_dir }}/LongCat-Video \
          --enable_compile
      else
        torchrun --nproc_per_node=$NUM_GPUS run_demo_text_to_video.py \
          --context_parallel_size=$NUM_GPUS \
          --checkpoint_dir={{ models_dir }}/LongCat-Video \
          --enable_compile
      fi

      # Restore original script
      mv run_demo_text_to_video.py.bak run_demo_text_to_video.py

      # Move outputs to /mnt/output
      TIMESTAMP=$(date +%Y%m%d_%H%M%S)
      for f in output*.mp4 *.mp4; do
        if [ -f "$f" ] && [[ "$f" != *".bak"* ]]; then
          mv "$f" "{{ output_dir }}/longcat_t2v_${TIMESTAMP}.mp4" 2>/dev/null && \
          echo "âœ… Saved: {{ output_dir }}/longcat_t2v_${TIMESTAMP}.mp4" && break
        fi
      done

      echo ""
      ls -la {{ output_dir }}/longcat_*.mp4 2>/dev/null | tail -5
    mode: '0755'
    owner: ubuntu
    group: ubuntu
  tags: [setup-longcat]

- name: Create LongCat I2V helper script (official approach)
  copy:
    dest: "{{ app_dir }}/longcat_i2v.sh"
    content: |
      #!/bin/bash
      # LongCat Image-to-Video - Official approach with torchrun
      # Usage: longcat_i2v.sh <image_path> "prompt" [num_gpus]

      IMAGE_PATH="${1}"
      PROMPT="${2:-A person walking forward}"
      NUM_GPUS="${3:-4}"

      if [ -z "$IMAGE_PATH" ]; then
        echo "Usage: longcat_i2v.sh <image_path> [prompt] [num_gpus]"
        echo "Example: longcat_i2v.sh /mnt/output/character.png 'Doctor walking in hospital'"
        exit 1
      fi

      source {{ app_dir }}/venv/bin/activate
      cd {{ models_dir }}/LongCat-Video-code

      echo "ðŸ± LongCat Image-to-Video (Official)"
      echo "   GPUs: $NUM_GPUS (context parallelism)"
      echo "   Compile: enabled"
      echo "   Image: $IMAGE_PATH"
      echo "   Prompt: $PROMPT"
      echo ""

      # Clear GPU memory
      python3 -c "import torch; [torch.cuda.empty_cache() for _ in range(torch.cuda.device_count())]" 2>/dev/null

      # Backup original script
      cp run_demo_image_to_video.py run_demo_image_to_video.py.bak

      # Replace prompt and image_path in script
      ESCAPED_PROMPT=$(echo "$PROMPT" | sed 's/[&/\]/\\&/g' | sed "s/'/\\\\'/g")
      ESCAPED_IMAGE=$(echo "$IMAGE_PATH" | sed 's/[&/\]/\\&/g')
      sed -i "s|prompt = \".*\"|prompt = \"$ESCAPED_PROMPT\"|" run_demo_image_to_video.py
      sed -i "s|image_path = \".*\"|image_path = \"$ESCAPED_IMAGE\"|" run_demo_image_to_video.py

      # Run with official command
      if [ "$NUM_GPUS" -eq 1 ]; then
        torchrun run_demo_image_to_video.py \
          --checkpoint_dir={{ models_dir }}/LongCat-Video \
          --enable_compile
      else
        torchrun --nproc_per_node=$NUM_GPUS run_demo_image_to_video.py \
          --context_parallel_size=$NUM_GPUS \
          --checkpoint_dir={{ models_dir }}/LongCat-Video \
          --enable_compile
      fi

      # Restore original script
      mv run_demo_image_to_video.py.bak run_demo_image_to_video.py

      # Move outputs to /mnt/output
      TIMESTAMP=$(date +%Y%m%d_%H%M%S)
      for f in output*.mp4 *.mp4; do
        if [ -f "$f" ] && [[ "$f" != *".bak"* ]]; then
          mv "$f" "{{ output_dir }}/longcat_i2v_${TIMESTAMP}.mp4" 2>/dev/null && \
          echo "âœ… Saved: {{ output_dir }}/longcat_i2v_${TIMESTAMP}.mp4" && break
        fi
      done

      echo ""
      ls -la {{ output_dir }}/longcat_i2v_*.mp4 2>/dev/null | tail -5
    mode: '0755'
    owner: ubuntu
    group: ubuntu
  tags: [setup-longcat]

- name: Create LongCat Video-Continuation helper script (official approach)
  copy:
    dest: "{{ app_dir }}/longcat_continue.sh"
    content: |
      #!/bin/bash
      # LongCat Video-Continuation - Official approach with torchrun
      # Usage: longcat_continue.sh <video_path> "prompt" [num_gpus]

      VIDEO_PATH="${1}"
      PROMPT="${2:-Continue the video naturally}"
      NUM_GPUS="${3:-4}"

      if [ -z "$VIDEO_PATH" ]; then
        echo "Usage: longcat_continue.sh <video_path> [prompt] [num_gpus]"
        echo "Example: longcat_continue.sh /mnt/output/scene1.mp4 'Doctor continues explaining'"
        exit 1
      fi

      source {{ app_dir }}/venv/bin/activate
      cd {{ models_dir }}/LongCat-Video-code

      echo "ðŸ± LongCat Video-Continuation (Official)"
      echo "   GPUs: $NUM_GPUS (context parallelism)"
      echo "   Compile: enabled"
      echo "   Video: $VIDEO_PATH"
      echo "   Prompt: $PROMPT"
      echo ""

      # Clear GPU memory
      python3 -c "import torch; [torch.cuda.empty_cache() for _ in range(torch.cuda.device_count())]" 2>/dev/null

      # Backup original script
      cp run_demo_video_continuation.py run_demo_video_continuation.py.bak

      # Replace prompt and video_path in script
      ESCAPED_PROMPT=$(echo "$PROMPT" | sed 's/[&/\]/\\&/g' | sed "s/'/\\\\'/g")
      ESCAPED_VIDEO=$(echo "$VIDEO_PATH" | sed 's/[&/\]/\\&/g')
      sed -i "s|prompt = \".*\"|prompt = \"$ESCAPED_PROMPT\"|" run_demo_video_continuation.py
      sed -i "s|video_path = \".*\"|video_path = \"$ESCAPED_VIDEO\"|" run_demo_video_continuation.py

      # Run with official command
      if [ "$NUM_GPUS" -eq 1 ]; then
        torchrun run_demo_video_continuation.py \
          --checkpoint_dir={{ models_dir }}/LongCat-Video \
          --enable_compile
      else
        torchrun --nproc_per_node=$NUM_GPUS run_demo_video_continuation.py \
          --context_parallel_size=$NUM_GPUS \
          --checkpoint_dir={{ models_dir }}/LongCat-Video \
          --enable_compile
      fi

      # Restore original script
      mv run_demo_video_continuation.py.bak run_demo_video_continuation.py

      # Move outputs to /mnt/output
      TIMESTAMP=$(date +%Y%m%d_%H%M%S)
      for f in output*.mp4 *.mp4; do
        if [ -f "$f" ] && [[ "$f" != *".bak"* ]]; then
          mv "$f" "{{ output_dir }}/longcat_continue_${TIMESTAMP}.mp4" 2>/dev/null && \
          echo "âœ… Saved: {{ output_dir }}/longcat_continue_${TIMESTAMP}.mp4" && break
        fi
      done

      echo ""
      ls -la {{ output_dir }}/longcat_continue_*.mp4 2>/dev/null | tail -5
    mode: '0755'
    owner: ubuntu
    group: ubuntu
  tags: [setup-longcat]

- name: Create LongCat Long-Video helper script (official approach)
  copy:
    dest: "{{ app_dir }}/longcat_long.sh"
    content: |
      #!/bin/bash
      # LongCat Long-Video - Official approach with torchrun
      # Usage: longcat_long.sh "prompt" [num_gpus]

      PROMPT="${1:-A doctor explaining medical procedure in hospital}"
      NUM_GPUS="${2:-4}"

      source {{ app_dir }}/venv/bin/activate
      cd {{ models_dir }}/LongCat-Video-code

      echo "ðŸ± LongCat Long-Video (Official)"
      echo "   GPUs: $NUM_GPUS (context parallelism)"
      echo "   Compile: enabled"
      echo "   Prompt: $PROMPT"
      echo "   âš ï¸  This may take several minutes..."
      echo ""

      # Clear GPU memory
      python3 -c "import torch; [torch.cuda.empty_cache() for _ in range(torch.cuda.device_count())]" 2>/dev/null

      # Backup original script
      cp run_demo_long_video.py run_demo_long_video.py.bak

      # Replace prompt in script
      ESCAPED_PROMPT=$(echo "$PROMPT" | sed 's/[&/\]/\\&/g' | sed "s/'/\\\\'/g")
      sed -i "s|prompt = \".*\"|prompt = \"$ESCAPED_PROMPT\"|" run_demo_long_video.py

      # Run with official command
      if [ "$NUM_GPUS" -eq 1 ]; then
        torchrun run_demo_long_video.py \
          --checkpoint_dir={{ models_dir }}/LongCat-Video \
          --enable_compile
      else
        torchrun --nproc_per_node=$NUM_GPUS run_demo_long_video.py \
          --context_parallel_size=$NUM_GPUS \
          --checkpoint_dir={{ models_dir }}/LongCat-Video \
          --enable_compile
      fi

      # Restore original script
      mv run_demo_long_video.py.bak run_demo_long_video.py

      # Move outputs to /mnt/output
      TIMESTAMP=$(date +%Y%m%d_%H%M%S)
      for f in output*.mp4 *.mp4; do
        if [ -f "$f" ] && [[ "$f" != *".bak"* ]]; then
          mv "$f" "{{ output_dir }}/longcat_long_${TIMESTAMP}.mp4" 2>/dev/null && \
          echo "âœ… Saved: {{ output_dir }}/longcat_long_${TIMESTAMP}.mp4" && break
        fi
      done

      echo ""
      ls -la {{ output_dir }}/longcat_long_*.mp4 2>/dev/null | tail -5
    mode: '0755'
    owner: ubuntu
    group: ubuntu
  tags: [setup-longcat]

- name: Create LongCat Interactive-Video helper script (official approach)
  copy:
    dest: "{{ app_dir }}/longcat_interactive.sh"
    content: |
      #!/bin/bash
      # LongCat Interactive-Video - Official approach with torchrun
      # Usage: longcat_interactive.sh [num_gpus]

      NUM_GPUS="${1:-4}"

      source {{ app_dir }}/venv/bin/activate
      cd {{ models_dir }}/LongCat-Video-code

      echo "ðŸ± LongCat Interactive-Video (Official)"
      echo "   GPUs: $NUM_GPUS (context parallelism)"
      echo "   Compile: enabled"
      echo ""

      # Clear GPU memory
      python3 -c "import torch; [torch.cuda.empty_cache() for _ in range(torch.cuda.device_count())]" 2>/dev/null

      # Run with official command
      if [ "$NUM_GPUS" -eq 1 ]; then
        torchrun run_demo_interactive_video.py \
          --checkpoint_dir={{ models_dir }}/LongCat-Video \
          --enable_compile
      else
        torchrun --nproc_per_node=$NUM_GPUS run_demo_interactive_video.py \
          --context_parallel_size=$NUM_GPUS \
          --checkpoint_dir={{ models_dir }}/LongCat-Video \
          --enable_compile
      fi
    mode: '0755'
    owner: ubuntu
    group: ubuntu
  tags: [setup-longcat]

# ============================================
# FINAL STATUS
# ============================================
- name: Display LongCat setup complete
  debug:
    msg: |
      ==========================================
      âœ… LONGCAT-VIDEO SETUP COMPLETE
      ==========================================
      Code: {{ models_dir }}/LongCat-Video-code/
      Model: {{ models_dir }}/LongCat-Video/

      Official Mode: torchrun + context_parallel + torch.compile

      Helper Scripts (default: 4 GPUs):
      - ~/video-generation/longcat_t2v.sh "prompt" [gpus]         # Text-to-Video
      - ~/video-generation/longcat_i2v.sh img "prompt" [gpus]     # Image-to-Video
      - ~/video-generation/longcat_continue.sh vid "prompt" [gpus] # Video-Continuation
      - ~/video-generation/longcat_long.sh "prompt" [gpus]        # Long Video
      - ~/video-generation/longcat_interactive.sh [gpus]          # Interactive

      Examples:
      ~/video-generation/longcat_t2v.sh "Doctor in white coat explaining procedure"
      ~/video-generation/longcat_t2v.sh "Cat walking on beach" 2   # Use 2 GPUs
      ~/video-generation/longcat_i2v.sh /mnt/output/doctor.png "Doctor walking"
      ~/video-generation/longcat_continue.sh /mnt/output/scene1.mp4 "Continue scene"
      ~/video-generation/longcat_long.sh "Extended medical lecture"
      ==========================================
  tags: [setup-longcat]
