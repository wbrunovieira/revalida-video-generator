---
# Setup LongCat-Video for T2V, I2V, and Video-Continuation
# Run with: ansible-playbook playbook.yml --tags setup-longcat

- name: Display LongCat setup banner
  debug:
    msg: |
      ==========================================
      ðŸ± SETTING UP LONGCAT-VIDEO
      ==========================================
      Features:
      - 13.6B parameters (dense architecture)
      - Text-to-Video, Image-to-Video, Video-Continuation
      - Long video generation (minutes-long)
      - 720p, 30fps output
      - Multi-GPU with context parallelism
      - FlashAttention-2 support
      ==========================================

# ============================================
# INSTALL LONGCAT DEPENDENCIES
# ============================================
- name: Install LongCat base dependencies
  pip:
    name:
      - ninja
      - psutil
      - packaging
      - einops
      - omegaconf
      - decord
      - imageio
      - imageio-ffmpeg
    virtualenv: "{{ app_dir }}/venv"
  become_user: ubuntu
  tags: [setup-longcat]

- name: Check if flash-attn is installed
  shell: |
    source {{ app_dir }}/venv/bin/activate
    pip show flash-attn || echo "not_installed"
  register: flash_attn_check
  become_user: ubuntu
  changed_when: false
  tags: [setup-longcat]
  args:
    executable: /bin/bash

- name: Install flash-attn if not present
  pip:
    name: flash_attn==2.7.4.post1
    virtualenv: "{{ app_dir }}/venv"
  become_user: ubuntu
  when: "'not_installed' in flash_attn_check.stdout"
  tags: [setup-longcat]

# ============================================
# CLONE LONGCAT REPOSITORY
# ============================================
- name: Clone LongCat-Video repository
  git:
    repo: https://github.com/meituan-longcat/LongCat-Video.git
    dest: "{{ models_dir }}/LongCat-Video-code"
    version: main
    force: yes
  become_user: ubuntu
  tags: [setup-longcat]

- name: Install LongCat requirements (excluding flash-attn)
  shell: |
    source {{ app_dir }}/venv/bin/activate
    cd {{ models_dir }}/LongCat-Video-code
    # Install requirements excluding flash-attn (already installed separately)
    grep -v "flash-attn" requirements.txt | pip install -r /dev/stdin
  become_user: ubuntu
  tags: [setup-longcat]
  args:
    executable: /bin/bash
  ignore_errors: yes

- name: Ensure flash-attn is installed (pre-built wheel)
  shell: |
    source {{ app_dir }}/venv/bin/activate
    # Check if already installed
    if pip show flash-attn > /dev/null 2>&1; then
      echo "flash-attn already installed"
    else
      # Install pre-built wheel for PyTorch 2.6 + CUDA 12.4
      pip install flash-attn --no-build-isolation
    fi
  become_user: ubuntu
  tags: [setup-longcat]
  args:
    executable: /bin/bash
  ignore_errors: yes

# ============================================
# DOWNLOAD LONGCAT MODEL
# ============================================
- name: Check if LongCat model exists
  stat:
    path: "{{ models_dir }}/LongCat-Video/config.json"
  register: longcat_model_check
  tags: [setup-longcat]

- name: Download LongCat-Video model (~27GB)
  shell: |
    source {{ app_dir }}/venv/bin/activate
    cd {{ models_dir }}
    echo "ðŸ“¥ Downloading LongCat-Video (~27GB, will take 20-40 minutes)..."
    huggingface-cli download meituan-longcat/LongCat-Video --local-dir LongCat-Video
  become_user: ubuntu
  when: not longcat_model_check.stat.exists
  tags: [setup-longcat]
  args:
    executable: /bin/bash
  async: 7200  # 2 hour timeout
  poll: 60    # Check every 60 seconds

- name: Verify model downloaded successfully
  stat:
    path: "{{ models_dir }}/LongCat-Video/config.json"
  register: longcat_final_check
  tags: [setup-longcat]

- name: Display model download status
  debug:
    msg: |
      LongCat-Video model: {{ 'Downloaded âœ…' if longcat_final_check.stat.exists else 'Failed âŒ' }}
      Location: {{ models_dir }}/LongCat-Video/
  tags: [setup-longcat]

# ============================================
# CREATE HELPER SCRIPTS
# ============================================
- name: Create LongCat T2V custom script with CPU offloading
  copy:
    dest: "{{ models_dir }}/LongCat-Video-code/run_t2v_a10g.py"
    content: |
      #!/usr/bin/env python3
      """
      LongCat Text-to-Video with CPU offloading for A10G GPUs (24GB)
      Optimized to fit 13.6B model on 4x A10G
      """
      import os
      import sys
      import argparse
      import datetime
      import gc
      import PIL.Image
      import numpy as np

      import torch
      import torch.distributed as dist

      from transformers import AutoTokenizer, UMT5EncoderModel
      from torchvision.io import write_video

      from longcat_video.pipeline_longcat_video import LongCatVideoPipeline
      from longcat_video.modules.scheduling_flow_match_euler_discrete import FlowMatchEulerDiscreteScheduler
      from longcat_video.modules.autoencoder_kl_wan import AutoencoderKLWan
      from longcat_video.modules.longcat_video_dit import LongCatVideoTransformer3DModel
      from longcat_video.context_parallel import context_parallel_util
      from longcat_video.context_parallel.context_parallel_util import init_context_parallel


      def torch_gc():
          gc.collect()
          torch.cuda.empty_cache()
          torch.cuda.ipc_collect()


      def generate(args):
          prompt = args.prompt
          negative_prompt = "Bright tones, overexposed, static, blurred details, subtitles, style, works, paintings, images, static, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, misshapen limbs, fused fingers, still picture, messy background, three legs, many people in the background, walking backwards"

          checkpoint_dir = args.checkpoint_dir
          context_parallel_size = args.context_parallel_size
          output_dir = args.output_dir

          # Prepare distributed environment
          rank = int(os.environ.get('RANK', 0))
          num_gpus = torch.cuda.device_count()
          local_rank = rank % num_gpus
          torch.cuda.set_device(local_rank)

          if num_gpus > 1:
              dist.init_process_group(backend="nccl", timeout=datetime.timedelta(seconds=3600*24))
              global_rank = dist.get_rank()
              num_processes = dist.get_world_size()
          else:
              global_rank = 0
              num_processes = 1

          # Initialize context parallel
          init_context_parallel(context_parallel_size=context_parallel_size, global_rank=global_rank, world_size=num_processes)
          cp_size = context_parallel_util.get_cp_size()
          cp_split_hw = context_parallel_util.get_optimal_split(cp_size)

          print(f"[Rank {local_rank}] Loading models with CPU offloading...")

          # Load tokenizer (small, keep on CPU)
          tokenizer = AutoTokenizer.from_pretrained(checkpoint_dir, subfolder="tokenizer")

          # Load text encoder to CPU first, move to GPU only when needed
          text_encoder = UMT5EncoderModel.from_pretrained(
              checkpoint_dir,
              subfolder="text_encoder",
              torch_dtype=torch.bfloat16,
              low_cpu_mem_usage=True
          )

          # Load VAE with low memory
          vae = AutoencoderKLWan.from_pretrained(
              checkpoint_dir,
              subfolder="vae",
              torch_dtype=torch.bfloat16,
              low_cpu_mem_usage=True
          )

          # Load scheduler
          scheduler = FlowMatchEulerDiscreteScheduler.from_pretrained(
              checkpoint_dir,
              subfolder="scheduler"
          )

          # Load DiT with CPU offloading - this is the big one
          print(f"[Rank {local_rank}] Loading DiT model (13.6B params)...")
          dit = LongCatVideoTransformer3DModel.from_pretrained(
              checkpoint_dir,
              subfolder="dit",
              cp_split_hw=cp_split_hw,
              torch_dtype=torch.bfloat16,
              low_cpu_mem_usage=True
          )

          # Create pipeline
          pipe = LongCatVideoPipeline(
              tokenizer=tokenizer,
              text_encoder=text_encoder,
              vae=vae,
              scheduler=scheduler,
              dit=dit,
          )

          # Enable CPU offload for the pipeline
          print(f"[Rank {local_rank}] Enabling sequential CPU offload...")
          pipe.enable_sequential_cpu_offload(gpu_id=local_rank)

          torch_gc()

          global_seed = 42
          seed = global_seed + global_rank
          generator = torch.Generator(device=f"cuda:{local_rank}")
          generator.manual_seed(seed)

          print(f"[Rank {local_rank}] Generating video...")
          print(f"[Rank {local_rank}] Prompt: {prompt[:100]}...")

          # Generate at 480p first (less memory)
          output = pipe.generate_t2v(
              prompt=prompt,
              negative_prompt=negative_prompt,
              height=480,
              width=832,
              num_frames=93,
              num_inference_steps=50,
              guidance_scale=4.0,
              generator=generator,
          )[0]

          if local_rank == 0:
              os.makedirs(output_dir, exist_ok=True)
              output_tensor = torch.from_numpy(np.array(output))
              output_tensor = (output_tensor * 255).clamp(0, 255).to(torch.uint8)
              output_path = os.path.join(output_dir, "longcat_t2v_480p.mp4")
              write_video(output_path, output_tensor, fps=15, video_codec="libx264", options={"crf": "18"})
              print(f"âœ… Saved: {output_path}")

          del output
          torch_gc()

          if num_gpus > 1:
              dist.destroy_process_group()


      def main():
          parser = argparse.ArgumentParser()
          parser.add_argument("--context_parallel_size", type=int, default=1)
          parser.add_argument("--checkpoint_dir", type=str, required=True)
          parser.add_argument("--prompt", type=str, required=True)
          parser.add_argument("--output_dir", type=str, default="{{ output_dir }}")
          args = parser.parse_args()
          generate(args)


      if __name__ == "__main__":
          main()
    mode: '0755'
    owner: ubuntu
    group: ubuntu
  tags: [setup-longcat]

- name: Create LongCat T2V helper script
  copy:
    dest: "{{ app_dir }}/longcat_t2v.sh"
    content: |
      #!/bin/bash
      # LongCat Text-to-Video generation with CPU offloading
      # Usage: longcat_t2v.sh "your prompt here" [num_gpus]

      PROMPT="${1:-A cat walking on the beach at sunset}"
      NUM_GPUS="${2:-4}"

      source {{ app_dir }}/venv/bin/activate
      cd {{ models_dir }}/LongCat-Video-code

      echo "ðŸ± Generating video with LongCat (CPU offload mode)..."
      echo "Prompt: $PROMPT"
      echo "GPUs: $NUM_GPUS"
      echo ""

      # Clear GPU memory first
      python3 -c "import torch; torch.cuda.empty_cache()" 2>/dev/null

      # Set memory optimization environment variables
      export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True

      # Run with custom A10G-optimized script
      if [ "$NUM_GPUS" -eq 1 ]; then
        python3 run_t2v_a10g.py \
          --checkpoint_dir={{ models_dir }}/LongCat-Video \
          --prompt "$PROMPT" \
          --output_dir={{ output_dir }}
      else
        torchrun --nproc_per_node=$NUM_GPUS run_t2v_a10g.py \
          --context_parallel_size=$NUM_GPUS \
          --checkpoint_dir={{ models_dir }}/LongCat-Video \
          --prompt "$PROMPT" \
          --output_dir={{ output_dir }}
      fi

      echo ""
      echo "âœ… Done! Check {{ output_dir }}/"
      ls -la {{ output_dir }}/longcat_*.mp4 2>/dev/null | tail -5
    mode: '0755'
    owner: ubuntu
    group: ubuntu
  tags: [setup-longcat]

- name: Create LongCat I2V helper script
  copy:
    dest: "{{ app_dir }}/longcat_i2v.sh"
    content: |
      #!/bin/bash
      # LongCat Image-to-Video generation
      # Usage: longcat_i2v.sh "image_path" "your prompt here" [num_gpus]

      IMAGE_PATH="${1}"
      PROMPT="${2:-A person walking forward}"
      NUM_GPUS="${3:-4}"

      if [ -z "$IMAGE_PATH" ]; then
        echo "Usage: longcat_i2v.sh <image_path> [prompt] [num_gpus]"
        echo "Example: longcat_i2v.sh /mnt/output/character.png 'Doctor walking in hospital'"
        exit 1
      fi

      source {{ app_dir }}/venv/bin/activate
      cd {{ models_dir }}/LongCat-Video-code

      echo "ðŸ± Generating I2V with LongCat..."
      echo "Image: $IMAGE_PATH"
      echo "Prompt: $PROMPT"
      echo "GPUs: $NUM_GPUS"
      echo ""

      # Backup original script
      cp run_demo_image_to_video.py run_demo_image_to_video.py.bak

      # Replace prompt and image_path in script
      ESCAPED_PROMPT=$(echo "$PROMPT" | sed 's/[&/\]/\\&/g' | sed "s/'/\\\\'/g")
      ESCAPED_IMAGE=$(echo "$IMAGE_PATH" | sed 's/[&/\]/\\&/g')
      sed -i "s|prompt = \".*\"|prompt = \"$ESCAPED_PROMPT\"|" run_demo_image_to_video.py
      sed -i "s|image_path = \".*\"|image_path = \"$ESCAPED_IMAGE\"|" run_demo_image_to_video.py

      # Run generation
      torchrun --nproc_per_node=$NUM_GPUS run_demo_image_to_video.py \
        --context_parallel_size=$NUM_GPUS \
        --checkpoint_dir={{ models_dir }}/LongCat-Video

      # Restore original script
      mv run_demo_image_to_video.py.bak run_demo_image_to_video.py

      # Move outputs to /mnt/output with timestamp
      TIMESTAMP=$(date +%Y%m%d_%H%M%S)
      for f in output_i2v*.mp4; do
        if [ -f "$f" ]; then
          mv "$f" "{{ output_dir }}/longcat_i2v_${TIMESTAMP}_${f}"
          echo "âœ… Saved: {{ output_dir }}/longcat_i2v_${TIMESTAMP}_${f}"
        fi
      done

      echo ""
      echo "âœ… Done! Check {{ output_dir }}/"
      ls -la {{ output_dir }}/longcat_i2v_*.mp4 2>/dev/null | tail -5
    mode: '0755'
    owner: ubuntu
    group: ubuntu
  tags: [setup-longcat]

- name: Create LongCat Video-Continuation helper script
  copy:
    dest: "{{ app_dir }}/longcat_continue.sh"
    content: |
      #!/bin/bash
      # LongCat Video-Continuation generation
      # Usage: longcat_continue.sh "video_path" "your prompt here" [num_gpus]

      VIDEO_PATH="${1}"
      PROMPT="${2:-Continue the video naturally}"
      NUM_GPUS="${3:-4}"

      if [ -z "$VIDEO_PATH" ]; then
        echo "Usage: longcat_continue.sh <video_path> [prompt] [num_gpus]"
        echo "Example: longcat_continue.sh /mnt/output/scene1.mp4 'Doctor continues explaining'"
        exit 1
      fi

      source {{ app_dir }}/venv/bin/activate
      cd {{ models_dir }}/LongCat-Video-code

      echo "ðŸ± Continuing video with LongCat..."
      echo "Video: $VIDEO_PATH"
      echo "Prompt: $PROMPT"
      echo "GPUs: $NUM_GPUS"
      echo ""

      # Backup original script
      cp run_demo_video_continuation.py run_demo_video_continuation.py.bak

      # Replace prompt and video_path in script
      ESCAPED_PROMPT=$(echo "$PROMPT" | sed 's/[&/\]/\\&/g' | sed "s/'/\\\\'/g")
      ESCAPED_VIDEO=$(echo "$VIDEO_PATH" | sed 's/[&/\]/\\&/g')
      sed -i "s|prompt = \".*\"|prompt = \"$ESCAPED_PROMPT\"|" run_demo_video_continuation.py
      sed -i "s|video_path = \".*\"|video_path = \"$ESCAPED_VIDEO\"|" run_demo_video_continuation.py

      # Run generation
      torchrun --nproc_per_node=$NUM_GPUS run_demo_video_continuation.py \
        --context_parallel_size=$NUM_GPUS \
        --checkpoint_dir={{ models_dir }}/LongCat-Video

      # Restore original script
      mv run_demo_video_continuation.py.bak run_demo_video_continuation.py

      # Move outputs to /mnt/output with timestamp
      TIMESTAMP=$(date +%Y%m%d_%H%M%S)
      for f in output_continuation*.mp4 output_vc*.mp4; do
        if [ -f "$f" ]; then
          mv "$f" "{{ output_dir }}/longcat_continue_${TIMESTAMP}_${f}"
          echo "âœ… Saved: {{ output_dir }}/longcat_continue_${TIMESTAMP}_${f}"
        fi
      done

      echo ""
      echo "âœ… Done! Check {{ output_dir }}/"
      ls -la {{ output_dir }}/longcat_continue_*.mp4 2>/dev/null | tail -5
    mode: '0755'
    owner: ubuntu
    group: ubuntu
  tags: [setup-longcat]

- name: Create LongCat Long-Video helper script
  copy:
    dest: "{{ app_dir }}/longcat_long.sh"
    content: |
      #!/bin/bash
      # LongCat Long-Video generation (minutes-long)
      # Usage: longcat_long.sh "your prompt here" [num_gpus]

      PROMPT="${1:-A doctor explaining medical procedure in hospital}"
      NUM_GPUS="${2:-4}"

      source {{ app_dir }}/venv/bin/activate
      cd {{ models_dir }}/LongCat-Video-code

      echo "ðŸ± Generating LONG video with LongCat..."
      echo "Prompt: $PROMPT"
      echo "GPUs: $NUM_GPUS"
      echo "âš ï¸  This may take several minutes..."
      echo ""

      # Backup original script
      cp run_demo_long_video.py run_demo_long_video.py.bak

      # Replace prompt in script
      ESCAPED_PROMPT=$(echo "$PROMPT" | sed 's/[&/\]/\\&/g' | sed "s/'/\\\\'/g")
      sed -i "s|prompt = \".*\"|prompt = \"$ESCAPED_PROMPT\"|" run_demo_long_video.py

      # Run generation
      torchrun --nproc_per_node=$NUM_GPUS run_demo_long_video.py \
        --context_parallel_size=$NUM_GPUS \
        --checkpoint_dir={{ models_dir }}/LongCat-Video

      # Restore original script
      mv run_demo_long_video.py.bak run_demo_long_video.py

      # Move outputs to /mnt/output with timestamp
      TIMESTAMP=$(date +%Y%m%d_%H%M%S)
      for f in output_long*.mp4; do
        if [ -f "$f" ]; then
          mv "$f" "{{ output_dir }}/longcat_long_${TIMESTAMP}_${f}"
          echo "âœ… Saved: {{ output_dir }}/longcat_long_${TIMESTAMP}_${f}"
        fi
      done

      echo ""
      echo "âœ… Done! Check {{ output_dir }}/"
      ls -la {{ output_dir }}/longcat_long_*.mp4 2>/dev/null | tail -5
    mode: '0755'
    owner: ubuntu
    group: ubuntu
  tags: [setup-longcat]

# ============================================
# FINAL STATUS
# ============================================
- name: Display LongCat setup complete
  debug:
    msg: |
      ==========================================
      âœ… LONGCAT-VIDEO SETUP COMPLETE
      ==========================================
      Code: {{ models_dir }}/LongCat-Video-code/
      Model: {{ models_dir }}/LongCat-Video/

      Helper Scripts:
      - ~/video-generation/longcat_t2v.sh "prompt"      # Text-to-Video
      - ~/video-generation/longcat_i2v.sh img "prompt"  # Image-to-Video
      - ~/video-generation/longcat_continue.sh vid "prompt"  # Video-Continuation
      - ~/video-generation/longcat_long.sh "prompt"     # Long Video

      Examples:
      ~/video-generation/longcat_t2v.sh "Doctor in white coat explaining procedure"
      ~/video-generation/longcat_i2v.sh /mnt/output/doctor.png "Doctor walking in hospital"
      ~/video-generation/longcat_continue.sh /mnt/output/scene1.mp4 "Doctor continues speaking"
      ==========================================
  tags: [setup-longcat]
