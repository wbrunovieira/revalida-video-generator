---
- name: Setup Video Generation Server
  hosts: video_server
  gather_facts: yes
  become: true
  vars:
    app_dir: /home/ubuntu/video-generation
    models_dir: /mnt/models
    output_dir: /mnt/output

  tasks:
    - name: Display deployment information
      debug:
        msg: |
          ========================================
          üöÄ VIDEO GENERATION SERVER SETUP
          ========================================
          Server: {{ ansible_host }}
          Timestamp: {{ ansible_date_time.date }} {{ ansible_date_time.time }}
          ========================================

    # ============================================
    # STEP 1: SYSTEM UPDATE & ESSENTIAL PACKAGES
    # ============================================
    - name: Update apt cache
      apt:
        update_cache: yes
        cache_valid_time: 3600

    - name: Install essential packages
      apt:
        name:
          - build-essential
          - git
          - wget
          - curl
          - vim
          - htop
          - nvtop
          - tmux
          - python3-pip
          - python3-venv
          - awscli
          - jq
          - rsync
          - unzip
          - ffmpeg
        state: present

    # ============================================
    # STEP 2: MOUNT STORAGE (Simplified Architecture)
    # ============================================
    # Architecture:
    # - 1x 1500GB EBS -> /mnt/models (AI models - persistent)
    # - Instance Store 3.5TB -> /mnt/output (videos - ephemeral, sync to local)

    # Find and mount the EBS volume for models (1.5TB / 1500GB)
    - name: Find EBS volume for models
      shell: lsblk -d -n -o NAME,SIZE | grep -E '1\.5T|1500G|500G|450G|400G' | grep -v nvme0 | head -1 | awk '{print $1}'
      register: ebs_volume
      changed_when: false

    - name: Display detected EBS volume
      debug:
        msg: "üì¶ Detected EBS volume: /dev/{{ ebs_volume.stdout }}"
      when: ebs_volume.stdout != ""

    - name: Check if EBS volume is formatted
      shell: "file -s /dev/{{ ebs_volume.stdout }}"
      register: ebs_format_check
      changed_when: false
      when: ebs_volume.stdout != ""

    - name: Format EBS volume if needed
      filesystem:
        fstype: ext4
        dev: "/dev/{{ ebs_volume.stdout }}"
      when:
        - ebs_volume.stdout != ""
        - "': data' in ebs_format_check.stdout"

    - name: Remove /mnt/models symlink if exists (from old config)
      file:
        path: /mnt/models
        state: absent
      when: ebs_volume.stdout != ""

    - name: Create mount point /mnt/models
      file:
        path: /mnt/models
        state: directory
        owner: ubuntu
        group: ubuntu
        mode: '0755'

    - name: Mount EBS volume to /mnt/models
      mount:
        path: /mnt/models
        src: "/dev/{{ ebs_volume.stdout }}"
        fstype: ext4
        opts: defaults,nofail
        state: mounted
      when: ebs_volume.stdout != ""

    - name: Set ownership for models volume
      file:
        path: /mnt/models
        owner: ubuntu
        group: ubuntu
        recurse: no

    # Setup output on ephemeral Instance Store
    - name: Check if Instance Store is available
      stat:
        path: /opt/dlami/nvme
      register: instance_store

    - name: Create output directory on ephemeral storage
      file:
        path: /opt/dlami/nvme/output
        state: directory
        owner: ubuntu
        group: ubuntu
        mode: '0755'
      when: instance_store.stat.exists

    - name: Remove old /mnt/output if exists
      file:
        path: /mnt/output
        state: absent
      when: instance_store.stat.exists

    - name: Create symlink /mnt/output -> ephemeral storage
      file:
        src: /opt/dlami/nvme/output
        dest: /mnt/output
        state: link
        owner: ubuntu
        group: ubuntu
      when: instance_store.stat.exists

    - name: Fallback - Create /mnt/output directory if no ephemeral storage
      file:
        path: /mnt/output
        state: directory
        owner: ubuntu
        group: ubuntu
        mode: '0755'
      when: not instance_store.stat.exists

    - name: Display storage status
      debug:
        msg: |
          üì¶ Storage Configuration:
          - Models: /mnt/models (500GB EBS)
          - Output: /mnt/output -> {{ '/opt/dlami/nvme/output (ephemeral)' if instance_store.stat.exists else '/mnt/output (root volume)' }}

    # ============================================
    # STEP 3: VERIFY GPU (if present)
    # ============================================
    - name: Check if nvidia-smi exists
      stat:
        path: /usr/bin/nvidia-smi
      register: nvidia_smi

    - name: Get GPU information
      shell: nvidia-smi --query-gpu=name,memory.total,driver_version --format=csv
      register: gpu_info
      when: nvidia_smi.stat.exists
      changed_when: false

    - name: Display GPU info
      debug:
        msg: |
          GPU Information:
          {{ gpu_info.stdout }}
      when: nvidia_smi.stat.exists and gpu_info.rc == 0

    - name: Display no GPU message
      debug:
        msg: "‚ö†Ô∏è  No GPU detected - this is a CPU-only instance"
      when: not nvidia_smi.stat.exists

    # ============================================
    # STEP 4: PYTHON ENVIRONMENT SETUP
    # ============================================
    - name: Create application directory
      file:
        path: "{{ app_dir }}"
        state: directory
        owner: ubuntu
        group: ubuntu
        mode: '0755'

    - name: Check if venv exists
      stat:
        path: "{{ app_dir }}/venv"
      register: venv_stat

    - name: Create Python virtual environment
      command: python3 -m venv {{ app_dir }}/venv
      become_user: ubuntu
      when: not venv_stat.stat.exists

    - name: Upgrade pip in venv
      pip:
        name: pip
        state: latest
        virtualenv: "{{ app_dir }}/venv"
      become_user: ubuntu

    # Install PyTorch first (required by xformers)
    - name: Install PyTorch packages
      pip:
        name:
          - torch
          - torchvision
          - torchaudio
        virtualenv: "{{ app_dir }}/venv"
      become_user: ubuntu

    - name: Display PyTorch install complete
      debug:
        msg: "‚úÖ PyTorch installed successfully"

    # Install remaining ML packages (including xformers which needs torch)
    - name: Install remaining ML packages
      pip:
        name:
          - diffusers
          - transformers
          - accelerate
          - xformers
          - huggingface-hub
          - opencv-python
          - Pillow
          - numpy
          - scipy
          - jupyter
          - ipykernel
        virtualenv: "{{ app_dir }}/venv"
      become_user: ubuntu

    - name: Display ML packages install complete
      debug:
        msg: "‚úÖ All ML packages installed successfully"

    # ============================================
    # STEP 5: BASH ALIASES & HELPERS
    # ============================================
    - name: Copy bash aliases file
      copy:
        src: files/bashrc-additions.sh
        dest: /home/ubuntu/.bashrc-video-gen
        owner: ubuntu
        group: ubuntu
        mode: '0644'

    - name: Source aliases in .bashrc
      lineinfile:
        path: /home/ubuntu/.bashrc
        line: 'source ~/.bashrc-video-gen'
        state: present
        create: yes
      become_user: ubuntu

    # ============================================
    # STEP 6: CREATE HELPER SCRIPTS
    # ============================================
    - name: Create system status script
      copy:
        dest: /usr/local/bin/video-status
        content: |
          #!/bin/bash
          echo "=========================================="
          echo "VIDEO GENERATION SERVER STATUS"
          echo "=========================================="
          echo ""
          echo "üìä System Resources:"
          free -h | grep -E "Mem|Swap"
          echo ""
          echo "üíæ Disk Usage:"
          df -h | grep -E "Filesystem|/mnt|/$"
          echo ""
          if command -v nvidia-smi &> /dev/null; then
            echo "üéÆ GPU Status:"
            nvidia-smi --query-gpu=index,name,temperature.gpu,utilization.gpu,utilization.memory,memory.used,memory.total --format=csv
          else
            echo "‚ö†Ô∏è  No GPU detected"
          fi
          echo ""
          echo "üìÅ Models Directory: {{ models_dir }}"
          du -sh {{ models_dir }}/* 2>/dev/null | head -5 || echo "  (empty)"
          echo ""
          echo "üìπ Output Directory: {{ output_dir }}"
          du -sh {{ output_dir }}/* 2>/dev/null | head -5 || echo "  (empty)"
          echo "=========================================="
        mode: '0755'

    - name: Create model download helper script
      copy:
        dest: /usr/local/bin/download-model
        content: |
          #!/bin/bash
          # Download AI models using huggingface-cli

          MODEL=$1

          if [ -z "$MODEL" ]; then
            echo "Usage: download-model <model-name>"
            echo ""
            echo "Examples:"
            echo "  download-model tencent/HunyuanVideo"
            echo "  download-model feizhengcong/Ovi"
            echo "  download-model THUDM/CogVideoX-5b"
            echo ""
            exit 1
          fi

          cd {{ models_dir }}
          source {{ app_dir }}/venv/bin/activate

          MODEL_NAME=$(basename $MODEL)
          echo "üì• Downloading $MODEL to {{ models_dir }}/$MODEL_NAME"

          huggingface-cli download $MODEL --local-dir $MODEL_NAME
        mode: '0755'

    # ============================================
    # STEP 7: DOWNLOAD AI MODELS (Optional)
    # ============================================
    # Run with: ansible-playbook playbook.yml --tags download-models
    - name: Include model download tasks
      import_tasks: tasks/download-models.yml
      tags: [download-models, never]  # never = only runs when explicitly requested

    # Run with: ansible-playbook playbook.yml --tags debug-torch
    - name: Include PyTorch debug tasks
      import_tasks: tasks/debug-torch.yml
      tags: [debug-torch, never]  # never = only runs when explicitly requested

    # Run with: ansible-playbook playbook.yml --tags setup-cogvideox
    - name: Include CogVideoX setup tasks
      import_tasks: tasks/setup-cogvideox.yml
      tags: [setup-cogvideox, never]  # never = only runs when explicitly requested

    # Run with: ansible-playbook playbook.yml --tags test-cogvideox
    - name: Include CogVideoX test tasks
      import_tasks: tasks/test-cogvideox.yml
      tags: [test-cogvideox, never]  # never = only runs when explicitly requested

    # Run with: ansible-playbook playbook.yml --tags setup-ovi
    - name: Include Ovi setup tasks
      import_tasks: tasks/setup-ovi.yml
      tags: [setup-ovi, never]  # never = only runs when explicitly requested

    # Run with: ansible-playbook playbook.yml --tags test-ovi
    - name: Include Ovi test tasks
      import_tasks: tasks/test-ovi.yml
      tags: [test-ovi, never]  # never = only runs when explicitly requested

    # Run with: ansible-playbook playbook.yml --tags setup-wan14b
    - name: Include Wan14B Rapid setup tasks
      import_tasks: tasks/setup-wan14b.yml
      tags: [setup-wan14b, never]  # never = only runs when explicitly requested

    # Run with: ansible-playbook playbook.yml --tags setup-hunyuan
    - name: Include HunyuanVideo-1.5 setup tasks
      import_tasks: tasks/setup-hunyuan.yml
      tags: [setup-hunyuan, never]  # never = only runs when explicitly requested

    # Run with: ansible-playbook playbook.yml --tags setup-skyreels
    - name: Include SkyReels-V2 I2V setup tasks
      import_tasks: tasks/setup-skyreels.yml
      tags: [setup-skyreels, never]  # never = only runs when explicitly requested

    # Run with: ansible-playbook playbook.yml --tags setup-chatterbox
    - name: Include Chatterbox TTS setup tasks
      import_tasks: tasks/setup-chatterbox.yml
      tags: [setup-chatterbox, never]  # never = only runs when explicitly requested


    # ============================================
    # STEP 8: FINAL CHECKS & DISPLAY
    # ============================================
    - name: Get disk space
      shell: df -h /
      register: disk_space
      changed_when: false

    - name: Get memory info
      shell: free -h
      register: memory_info
      changed_when: false

    - name: Display setup summary
      debug:
        msg: |
          ========================================
          üéâ SETUP COMPLETED SUCCESSFULLY!
          ========================================

          üìÅ Directories Created:
             - Models:  {{ models_dir }}
             - Output:  {{ output_dir }}
             - App:     {{ app_dir }}

          üêç Python Environment:
             - Location: {{ app_dir }}/venv
             - Activate: source {{ app_dir }}/venv/bin/activate

          üõ†Ô∏è  Helper Commands:
             - video-status          # Show system status
             - download-model <name> # Download AI models

          üì¶ Next Steps:
             1. SSH into server: ssh ubuntu@{{ ansible_host }}
             2. Check status: video-status
             3. Download models: download-model tencent/HunyuanVideo
             4. Start generating videos!

          üíæ Disk Space:
          {{ disk_space.stdout }}

          üß† Memory:
          {{ memory_info.stdout }}

          ========================================
