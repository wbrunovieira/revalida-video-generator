---
- name: Setup Video Generation Server
  hosts: video_server
  gather_facts: yes
  become: true
  vars:
    app_dir: /home/ubuntu/video-generation
    models_dir: /mnt/models
    output_dir: /mnt/output

  tasks:
    - name: Display deployment information
      debug:
        msg: |
          ========================================
          üöÄ VIDEO GENERATION SERVER SETUP
          ========================================
          Server: {{ ansible_host }}
          Timestamp: {{ ansible_date_time.date }} {{ ansible_date_time.time }}
          ========================================

    # ============================================
    # STEP 1: SYSTEM UPDATE & ESSENTIAL PACKAGES
    # ============================================
    - name: Update apt cache
      apt:
        update_cache: yes
        cache_valid_time: 3600

    - name: Install essential packages
      apt:
        name:
          - build-essential
          - git
          - wget
          - curl
          - vim
          - htop
          - nvtop
          - tmux
          - python3-pip
          - python3-venv
          - awscli
          - jq
          - rsync
          - unzip
          - ffmpeg
        state: present

    # ============================================
    # STEP 2: MOUNT EBS VOLUMES
    # ============================================

    # Check if nvme1n1 is being used by LVM (Deep Learning AMI default)
    - name: Check if models volume is part of LVM
      shell: pvdisplay /dev/nvme1n1 2>/dev/null || echo "not_lvm"
      register: lvm_check
      changed_when: false
      ignore_errors: yes

    - name: Unmount LVM volume if present
      mount:
        path: /opt/dlami/nvme
        state: unmounted
      when: "'not_lvm' not in lvm_check.stdout"
      ignore_errors: yes

    - name: Remove LVM logical volume
      lvol:
        vg: vg.01
        lv: lv_ephemeral
        state: absent
        force: yes
      when: "'not_lvm' not in lvm_check.stdout"
      ignore_errors: yes

    - name: Remove LVM volume group
      lvg:
        vg: vg.01
        state: absent
      when: "'not_lvm' not in lvm_check.stdout"
      ignore_errors: yes

    - name: Remove LVM physical volume
      command: pvremove -ff /dev/nvme1n1
      when: "'not_lvm' not in lvm_check.stdout"
      ignore_errors: yes

    - name: Check if models volume is formatted
      shell: file -s /dev/nvme1n1
      register: models_volume_check
      changed_when: false
      ignore_errors: yes

    - name: Format models volume if needed
      filesystem:
        fstype: ext4
        dev: /dev/nvme1n1
        force: yes
      when: "'ext4' not in models_volume_check.stdout and ': data' in models_volume_check.stdout"

    - name: Check if output volume is formatted
      shell: file -s /dev/nvme2n1
      register: output_volume_check
      changed_when: false
      ignore_errors: yes

    - name: Format output volume if needed
      filesystem:
        fstype: ext4
        dev: /dev/nvme2n1
        force: yes
      when: "'ext4' not in output_volume_check.stdout and ': data' in output_volume_check.stdout"

    - name: Create mount points
      file:
        path: "{{ item }}"
        state: directory
        owner: ubuntu
        group: ubuntu
        mode: '0755'
      loop:
        - "{{ models_dir }}"
        - "{{ output_dir }}"

    - name: Mount models volume
      mount:
        path: "{{ models_dir }}"
        src: /dev/nvme1n1
        fstype: ext4
        opts: defaults,nofail
        state: mounted

    - name: Mount output volume
      mount:
        path: "{{ output_dir }}"
        src: /dev/nvme2n1
        fstype: ext4
        opts: defaults,nofail
        state: mounted

    - name: Set ownership for mounted volumes
      file:
        path: "{{ item }}"
        owner: ubuntu
        group: ubuntu
        recurse: yes
      loop:
        - "{{ models_dir }}"
        - "{{ output_dir }}"

    # ============================================
    # STEP 3: VERIFY GPU (if present)
    # ============================================
    - name: Check if nvidia-smi exists
      stat:
        path: /usr/bin/nvidia-smi
      register: nvidia_smi

    - name: Get GPU information
      shell: nvidia-smi --query-gpu=name,memory.total,driver_version --format=csv
      register: gpu_info
      when: nvidia_smi.stat.exists
      changed_when: false

    - name: Display GPU info
      debug:
        msg: |
          GPU Information:
          {{ gpu_info.stdout }}
      when: nvidia_smi.stat.exists and gpu_info.rc == 0

    - name: Display no GPU message
      debug:
        msg: "‚ö†Ô∏è  No GPU detected - this is a CPU-only instance"
      when: not nvidia_smi.stat.exists

    # ============================================
    # STEP 4: PYTHON ENVIRONMENT SETUP
    # ============================================
    - name: Create application directory
      file:
        path: "{{ app_dir }}"
        state: directory
        owner: ubuntu
        group: ubuntu
        mode: '0755'

    - name: Check if venv exists
      stat:
        path: "{{ app_dir }}/venv"
      register: venv_stat

    - name: Create Python virtual environment
      command: python3 -m venv {{ app_dir }}/venv
      become_user: ubuntu
      when: not venv_stat.stat.exists

    - name: Upgrade pip in venv
      pip:
        name: pip
        state: latest
        virtualenv: "{{ app_dir }}/venv"
      become_user: ubuntu

    # Install PyTorch first (required by xformers)
    - name: Install PyTorch packages
      pip:
        name:
          - torch
          - torchvision
          - torchaudio
        virtualenv: "{{ app_dir }}/venv"
      become_user: ubuntu

    - name: Display PyTorch install complete
      debug:
        msg: "‚úÖ PyTorch installed successfully"

    # Install remaining ML packages (including xformers which needs torch)
    - name: Install remaining ML packages
      pip:
        name:
          - diffusers
          - transformers
          - accelerate
          - xformers
          - huggingface-hub
          - opencv-python
          - Pillow
          - numpy
          - scipy
          - jupyter
          - ipykernel
        virtualenv: "{{ app_dir }}/venv"
      become_user: ubuntu

    - name: Display ML packages install complete
      debug:
        msg: "‚úÖ All ML packages installed successfully"

    # ============================================
    # STEP 5: BASH ALIASES & HELPERS
    # ============================================
    - name: Copy bash aliases file
      copy:
        src: files/bashrc-additions.sh
        dest: /home/ubuntu/.bashrc-video-gen
        owner: ubuntu
        group: ubuntu
        mode: '0644'

    - name: Source aliases in .bashrc
      lineinfile:
        path: /home/ubuntu/.bashrc
        line: 'source ~/.bashrc-video-gen'
        state: present
        create: yes
      become_user: ubuntu

    # ============================================
    # STEP 6: CREATE HELPER SCRIPTS
    # ============================================
    - name: Create system status script
      copy:
        dest: /usr/local/bin/video-status
        content: |
          #!/bin/bash
          echo "=========================================="
          echo "VIDEO GENERATION SERVER STATUS"
          echo "=========================================="
          echo ""
          echo "üìä System Resources:"
          free -h | grep -E "Mem|Swap"
          echo ""
          echo "üíæ Disk Usage:"
          df -h | grep -E "Filesystem|/mnt|/$"
          echo ""
          if command -v nvidia-smi &> /dev/null; then
            echo "üéÆ GPU Status:"
            nvidia-smi --query-gpu=index,name,temperature.gpu,utilization.gpu,utilization.memory,memory.used,memory.total --format=csv
          else
            echo "‚ö†Ô∏è  No GPU detected"
          fi
          echo ""
          echo "üìÅ Models Directory: {{ models_dir }}"
          du -sh {{ models_dir }}/* 2>/dev/null | head -5 || echo "  (empty)"
          echo ""
          echo "üìπ Output Directory: {{ output_dir }}"
          du -sh {{ output_dir }}/* 2>/dev/null | head -5 || echo "  (empty)"
          echo "=========================================="
        mode: '0755'

    - name: Create model download helper script
      copy:
        dest: /usr/local/bin/download-model
        content: |
          #!/bin/bash
          # Download AI models using huggingface-cli

          MODEL=$1

          if [ -z "$MODEL" ]; then
            echo "Usage: download-model <model-name>"
            echo ""
            echo "Examples:"
            echo "  download-model tencent/HunyuanVideo"
            echo "  download-model yihao-meng/HoloCine"
            echo "  download-model THUDM/CogVideoX-5b"
            echo ""
            exit 1
          fi

          cd {{ models_dir }}
          source {{ app_dir }}/venv/bin/activate

          MODEL_NAME=$(basename $MODEL)
          echo "üì• Downloading $MODEL to {{ models_dir }}/$MODEL_NAME"

          huggingface-cli download $MODEL --local-dir $MODEL_NAME
        mode: '0755'

    # ============================================
    # STEP 7: DOWNLOAD AI MODELS (Optional)
    # ============================================
    # Run with: ansible-playbook playbook.yml --tags download-models
    - name: Include model download tasks
      import_tasks: tasks/download-models.yml
      tags: [download-models, never]  # never = only runs when explicitly requested

    # Run with: ansible-playbook playbook.yml --tags setup-hunyuan
    - name: Include HunyuanVideo setup tasks
      import_tasks: tasks/setup-hunyuan.yml
      tags: [setup-hunyuan, never]  # never = only runs when explicitly requested

    # Run with: ansible-playbook playbook.yml --tags test-hunyuan
    - name: Include HunyuanVideo test tasks
      import_tasks: tasks/test-hunyuan.yml
      tags: [test-hunyuan, never]  # never = only runs when explicitly requested

    # Run with: ansible-playbook playbook.yml --tags debug-torch
    - name: Include PyTorch debug tasks
      import_tasks: tasks/debug-torch.yml
      tags: [debug-torch, never]  # never = only runs when explicitly requested

    # Run with: ansible-playbook playbook.yml --tags setup-cogvideox
    - name: Include CogVideoX setup tasks
      import_tasks: tasks/setup-cogvideox.yml
      tags: [setup-cogvideox, never]  # never = only runs when explicitly requested

    # Run with: ansible-playbook playbook.yml --tags test-cogvideox
    - name: Include CogVideoX test tasks
      import_tasks: tasks/test-cogvideox.yml
      tags: [test-cogvideox, never]  # never = only runs when explicitly requested

    # ============================================
    # STEP 8: FINAL CHECKS & DISPLAY
    # ============================================
    - name: Get disk space
      shell: df -h /
      register: disk_space
      changed_when: false

    - name: Get memory info
      shell: free -h
      register: memory_info
      changed_when: false

    - name: Display setup summary
      debug:
        msg: |
          ========================================
          üéâ SETUP COMPLETED SUCCESSFULLY!
          ========================================

          üìÅ Directories Created:
             - Models:  {{ models_dir }}
             - Output:  {{ output_dir }}
             - App:     {{ app_dir }}

          üêç Python Environment:
             - Location: {{ app_dir }}/venv
             - Activate: source {{ app_dir }}/venv/bin/activate

          üõ†Ô∏è  Helper Commands:
             - video-status          # Show system status
             - download-model <name> # Download AI models

          üì¶ Next Steps:
             1. SSH into server: ssh ubuntu@{{ ansible_host }}
             2. Check status: video-status
             3. Download models: download-model tencent/HunyuanVideo
             4. Start generating videos!

          üíæ Disk Space:
          {{ disk_space.stdout }}

          üß† Memory:
          {{ memory_info.stdout }}

          ========================================
